{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = pickle.load( open( \"data/clean_words.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_ready)\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=5,\n",
    "    random_state=100,\n",
    "    update_every=1,\n",
    "    chunksize=100,\n",
    "    passes=100,\n",
    "    alpha=\"auto\",\n",
    "    iterations=100,\n",
    "    per_word_topics=True,\n",
    ")\n",
    "\n",
    "# print(lda_model.print_topics())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(lda_model, open(\"data/lda_model_v1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open( \"data/data.pickle\", \"rb\" ) )\n",
    "lda_model = pickle.load( open( \"data/lda_model_v1.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(\n",
    "                    pd.Series([int(topic_num), round(prop_topic, 4), topic_keywords]),\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = [\"Dominant_Topic\", \"Perc_Contribution\", \"Topic_Keywords\"]\n",
    "\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(\n",
    "    ldamodel=lda_model, corpus=corpus, texts=data_ready\n",
    ")\n",
    "\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = [\n",
    "    \"Document_No\",\n",
    "    \"Dominant_Topic\",\n",
    "    \"Topic_Perc_Contrib\",\n",
    "    \"Keywords\",\n",
    "    \"Text\",\n",
    "]\n",
    "df_dominant_topic.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby(\"Dominant_Topic\")\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat(\n",
    "        [\n",
    "            sent_topics_sorteddf_mallet,\n",
    "            grp.sort_values([\"Perc_Contribution\"], ascending=False).head(1),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "# Reset Index\n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = [\n",
    "    \"Topic_Num\",\n",
    "    \"Topic_Perc_Contrib\",\n",
    "    \"Keywords\",\n",
    "    \"Representative Text\",\n",
    "]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df = pd.read_csv(\"data/raw_mail_all.csv\")\n",
    "email_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_with_topic = pd.concat([email_df, df_dominant_topic], axis=1)\n",
    "email_with_topic.to_csv(\"data/email_with_topic_v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(f\"all_v1\"))\n",
    "\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(f\"all_v1\") +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc3f249eb8269fe0400e72a0f427e175b24dd81fbe32ee1422536ef70707752a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
